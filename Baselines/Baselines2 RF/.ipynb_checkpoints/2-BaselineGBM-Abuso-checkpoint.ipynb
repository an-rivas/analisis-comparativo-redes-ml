{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "https://catboost.ai/en/docs/references/training-parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from funciones import CargarPandasDatasetCategoricos, CargarPandasDataset, BorrarColumnas, obtenerOhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "from sklearn import tree #La versión que tengo es 0.24.1 y está disponible apartir de la 0.21\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import export_text\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import shap\n",
    "\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.experimental import enable_hist_gradient_boosting # enable experimental features first in order to import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endireh = CargarPandasDataset('datasets/endireh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23669, 49)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endireh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo nos quedamos con las que sufieron 'Abuso y violencia'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminando los de atención no autorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "endireh.drop(endireh[endireh[\"P9_8\"]==2].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'abuso y violencia' y ambos sean 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "endireh[endireh[\"P9_8\"]>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22200, 49)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endireh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo la variable objetivo _y_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = endireh['P9_8'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser el análisis nacional borramos la variable _REGION_ que no pertenece a este estudio en particular y Elimino _y_ del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "endireh.drop(columns=['P9_8', 'REGION'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(endireh, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ninguno(0):\t76%\n",
      "Abuso y violencia(1):\t24%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f00d5203908>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,j in zip(['Ninguno(0)', 'Abuso y violencia(1)'], y.value_counts()/y.value_counts().sum()):\n",
    "    print(f'{i}:\\t{round(j*100)}%')\n",
    "y.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.ensemble.HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "est = HistGradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "est.score(endireh, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pred_train = est.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1_score(y_test, pred_train, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost.CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           custom_metric=\"F1\",\n",
    "                           use_best_model=False,\n",
    "                           verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f00d4e32320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the prediction using the resulting model\n",
    "preds_class = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where(endireh.dtypes == np.object)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = model.get_feature_importance(\n",
    "    Pool(X_test, label=y_test, cat_features=categorical_features_indices),\n",
    "    type=\"ShapValues\",\n",
    ") \n",
    "shap_values = shap_values[:, :-1] \n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.12422784,  0.        ,  0.        ,  0.        , 99.87577216,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance(Pool(X_test, label=y_test, cat_features=categorical_features_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 por clase\n",
    "\n",
    "devuelve precision, recall, f1 y ocurrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1.]), array([1., 1.]), array([1., 1.]), array([5598, 1728]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, preds_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/using-a-custom-metric-in-catboost-classification-as-regression-1ad42b2e7d\n",
    "#https://mljar.com/blog/catboost-custom-eval-metric/\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class bin_f1(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight=None):\n",
    "        # approxes - list of list-like objects (one object per approx dimension)\n",
    "        # target - list-like object\n",
    "        # weight - list-like object, can be None\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        \n",
    "        preds = np.array(approxes[0])\n",
    "        target = np.array(target)\n",
    "        print(min(preds), max(preds))\n",
    "        \n",
    "        f1 = precision_recall_fscore_support(target, preds)[2][1]\n",
    "        return f1, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar los mejores parámetros con _Grid Search_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos los parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check:\n",
    "1. fold_permutation_block\n",
    "2. output_borders\n",
    "3. auto_class_weights, and\n",
    "4. feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13650"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = ParameterGrid(\n",
    "                    {\n",
    "                     'grow_policy'        : ['Depthwise', 'SymmetricTree', 'Lossguide'], # The tree growing policy. \n",
    "                     'depth'              : range(4, 17), # max_depth\n",
    "                     'learning_rate'      : [i/100 for i in range(85,95)], # eta\n",
    "                     'iterations'         : [100],\n",
    "                     'min_data_in_leaf'   : range(90, 151, 10), # min_samples_split\n",
    "                     'random_strength'    : [1+(i/10) for i in range(1,6)], # The amount of randomness to use for scoring splits\n",
    "                    }\n",
    "                )\n",
    "\n",
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el diccionario que guadará los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {'params': [], 'f1_abuso':[]}\n",
    "importances = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop para ajustar un modelo con cada combinación de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where(endireh.dtypes == np.object)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando modelos para 13650 combinaciones de parámetros.\n",
      "\n",
      "-3.11107162208388 3.1108662422972997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/python-package/catboost/helpers.cpp:42: Traceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-19-3060a4c89cac>\", line 21:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-19-3060a4c89cac>\", line 21, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-25-b36bb383f84c>\", line 23:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-25-b36bb383f84c>\", line 23, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-30-0415cc0da44c>\", line 25:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-30-0415cc0da44c>\", line 25, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-33-eff8857c45e3>\", line 24:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-33-eff8857c45e3>\", line 24, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-19-3060a4c89cac>\", line 21:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._MetricEval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3060a4c89cac>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, approxes, target, weight)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1465\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 93\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-25-b36bb383f84c>\", line 23:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._MetricEval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b36bb383f84c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, approxes, target, weight)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1465\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 93\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-30-0415cc0da44c>\", line 25:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._MetricEval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0415cc0da44c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, approxes, target, weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1465\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 93\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-33-eff8857c45e3>\", line 24:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._MetricEval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._try_jit_method.new_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-eff8857c45e3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, approxes, target, weight)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1465\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 93\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   4768\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4769\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4770\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[1;32m   4771\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2092\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m             )\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/python-package/catboost/helpers.cpp:42: Traceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-19-3060a4c89cac>\", line 21:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-19-3060a4c89cac>\", line 21, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-25-b36bb383f84c>\", line 23:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-25-b36bb383f84c>\", line 23, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-30-0415cc0da44c>\", line 25:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-30-0415cc0da44c>\", line 25, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1527, in _catboost._try_jit_method.new_method\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 420, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"/home/arivas/.local/lib/python3.6/site-packages/numba/core/dispatcher.py\", line 361, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'precision_recall_fscore_support': Cannot determine Numba type of <class 'function'>\n\nFile \"<ipython-input-33-eff8857c45e3>\", line 24:\n    def evaluate(self, approxes, target, weight=None):\n        <source elided>\n        \n        f1 = precision_recall_fscore_support(target, preds)[2][1]\n        ^\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 1319, in _catboost._MetricEval\n  File \"_catboost.pyx\", line 1532, in _catboost._try_jit_method.new_method\n  File \"<ipython-input-33-eff8857c45e3>\", line 24, in evaluate\n    f1 = precision_recall_fscore_support(target, preds)[2][1]\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1465, in precision_recall_fscore_support\n    pos_label)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 1277, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/home/arivas/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of binary and continuous targets\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Creando modelos para {len(param_grid)} combinaciones de parámetros.\\n')\n",
    "\n",
    "for i,params in enumerate(list(param_grid)):\n",
    "    if i >= 0:\n",
    "        model = CatBoostClassifier(\n",
    "                               eval_metric            = bin_f1(),\n",
    "                               leaf_estimation_method = \"Gradient\", # The method used to calculate the values in leaves.\n",
    "                               boosting_type          = 'Plain',\n",
    "                               verbose                = 0,\n",
    "                               use_best_model         = True,\n",
    "                               random_seed            = 5,\n",
    "                               ** params\n",
    "                    )\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(endireh, y, test_size=0.33)\n",
    "\n",
    "        # train the model if use_best_model=False\n",
    "        #model.fit(X=X_train, y=y_train)\n",
    "\n",
    "        # train the model if use_best_model=True\n",
    "        model.fit(X=X_train, y=y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "        resultados['params'].append(params)\n",
    "        f1 = precision_recall_fscore_support(y_test, preds_class)[2]\n",
    "        resultados['f1_abuso'].append(f1[1])\n",
    "\n",
    "        importances.append(model.get_feature_importance(Pool(X_test, label=y_test, cat_features=categorical_features_indices)))\n",
    "\n",
    "        if i%450 == 0 or i==len(param_grid):\n",
    "            print(f\"Modelo {i}: {params} \\u2713 ({resultados['f1'][-1]})\")\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. 3 de febrero de 2022 20160 combinaciones\n",
    "\n",
    "    param_grid = ParameterGrid(\n",
    "                    {\n",
    "                     'grow_policy'        : ['Depthwise', 'SymmetricTree', 'Lossguide'], # The tree growing policy. \n",
    "                     'depth'              : range(4, 17, 2), # max_depth\n",
    "                     'learning_rate'      : [i/100 for i in range(85,95)], # eta\n",
    "                     'iterations'         : [100],\n",
    "                     'min_data_in_leaf'   : range(90, 151, 10), # min_samples_split\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "Puesto a las 9:55 horas. Sin experiencia previa. Terminó 23:30 hrs. Duró 6:30 hrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados1 = pd.DataFrame(resultados)\n",
    "resultados1 = pd.concat([resultados1, resultados1['params'].apply(pd.Series)], axis=1)\n",
    "resultados1 = resultados1.drop(columns = 'params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_ninguno</th>\n",
       "      <th>f1_abuso</th>\n",
       "      <th>depth</th>\n",
       "      <th>grow_policy</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>random_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773016</td>\n",
       "      <td>0.269928</td>\n",
       "      <td>9</td>\n",
       "      <td>Lossguide</td>\n",
       "      <td>100</td>\n",
       "      <td>0.92</td>\n",
       "      <td>150</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771285</td>\n",
       "      <td>0.269605</td>\n",
       "      <td>5</td>\n",
       "      <td>Depthwise</td>\n",
       "      <td>100</td>\n",
       "      <td>0.88</td>\n",
       "      <td>100</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773986</td>\n",
       "      <td>0.268363</td>\n",
       "      <td>5</td>\n",
       "      <td>Lossguide</td>\n",
       "      <td>100</td>\n",
       "      <td>0.92</td>\n",
       "      <td>150</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12240</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770486</td>\n",
       "      <td>0.268153</td>\n",
       "      <td>15</td>\n",
       "      <td>SymmetricTree</td>\n",
       "      <td>100</td>\n",
       "      <td>0.94</td>\n",
       "      <td>140</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770307</td>\n",
       "      <td>0.267581</td>\n",
       "      <td>11</td>\n",
       "      <td>Depthwise</td>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>150</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770017</td>\n",
       "      <td>0.266933</td>\n",
       "      <td>5</td>\n",
       "      <td>Lossguide</td>\n",
       "      <td>100</td>\n",
       "      <td>0.87</td>\n",
       "      <td>120</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.768609</td>\n",
       "      <td>0.266856</td>\n",
       "      <td>9</td>\n",
       "      <td>SymmetricTree</td>\n",
       "      <td>100</td>\n",
       "      <td>0.89</td>\n",
       "      <td>110</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774516</td>\n",
       "      <td>0.266473</td>\n",
       "      <td>7</td>\n",
       "      <td>Lossguide</td>\n",
       "      <td>100</td>\n",
       "      <td>0.89</td>\n",
       "      <td>140</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1  f1_ninguno  f1_abuso  depth    grow_policy  iterations  \\\n",
       "6227   1.0    0.773016  0.269928      9      Lossguide         100   \n",
       "1164   1.0    0.771285  0.269605      5      Depthwise         100   \n",
       "2029   1.0    0.773986  0.268363      5      Lossguide         100   \n",
       "12240  1.0    0.770486  0.268153     15  SymmetricTree         100   \n",
       "7381   1.0    0.770307  0.267581     11      Depthwise         100   \n",
       "1838   1.0    0.770017  0.266933      5      Lossguide         100   \n",
       "5750   1.0    0.768609  0.266856      9  SymmetricTree         100   \n",
       "4017   1.0    0.774516  0.266473      7      Lossguide         100   \n",
       "\n",
       "       learning_rate  min_data_in_leaf  random_strength  \n",
       "6227            0.92               150              1.3  \n",
       "1164            0.88               100              1.5  \n",
       "2029            0.92               150              1.5  \n",
       "12240           0.94               140              1.1  \n",
       "7381            0.85               150              1.2  \n",
       "1838            0.87               120              1.4  \n",
       "5750            0.89               110              1.1  \n",
       "4017            0.89               140              1.3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados1.sort_values('f1_abuso', ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"FI/feature_importance_GBM_A1.txt\", \"w\")\n",
    "for element in importances[list(resultados1.index)[0]]:\n",
    "    textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
