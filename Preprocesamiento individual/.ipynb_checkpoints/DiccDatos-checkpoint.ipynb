{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntar los diccionarios de datos de las variables del dataframe resultante\n",
    "\n",
    "Se obtienen las nemónicos de los diccionarios de datos correspondientes y se juntan con la descripcion de los catálogos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_dicc_de_datos = [\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tviv_endireh_2016/diccionario_de_datos/diccionario_de_datos_tviv_endireh_2016.csv\",\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tsdem_endireh_2016/diccionario_de_datos/diccionario_de_datos_tsdem_endireh_2016.csv\",\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tb_sec_iii_endireh_2016/diccionario_de_datos/diccionario_de_datos_tb_sec_iii_endireh_2016.csv\",\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tb_sec_ix_endireh_2016/diccionario_de_datos/diccionario_de_datos_tb_sec_ix_endireh_2016.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_catalogo_de_datos = [\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tviv_endireh_2016/catalogos\",\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tsdem_endireh_2016/catalogos\",\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tb_sec_iii_endireh_2016/catalogos\",\n",
    "    \"../../conjunto_de_datos_endireh_2016_csv/conjunto_de_datos_tb_sec_ix_endireh_2016/catalogos\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_parcial = \"datasets/endireh.csv\"\n",
    "\n",
    "endireh = pd.read_csv(ruta_parcial, na_values=['\\r'])\n",
    "\n",
    "columnas = list(endireh.columns)\n",
    "columnas = [c.lower() for c in columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = {'NOMBRE_CAMPO':[],\n",
    "        'NEMONICO': [],\n",
    "        'TIPO':[],\n",
    "        'LONGITUD':[],\n",
    "        'RANGO_CLAVES':[],\n",
    "        'DESCRIP':[]}\n",
    "aux = pd.DataFrame.from_dict(dicc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ruta_parcial,ruta_catalogos in zip(lista_de_dicc_de_datos, lista_catalogo_de_datos):\n",
    "    ###################################################\n",
    "    ###CARGO EL DICCIONARIO DE DATOS CORRESPONDIENTE###\n",
    "    ###################################################\n",
    "    diccionario_datos = pd.read_csv(ruta_parcial)\n",
    "    #limpio de espacios con expresiones regulares\n",
    "    diccionario_datos = diccionario_datos.replace(regex=r'(\\w+)(\\W)*\\r', value=r'\\1') \n",
    "    \n",
    "    #agregar la columna de descripcion\n",
    "    diccionario_datos.insert(5, 'DESCRIP', np.nan)\n",
    "    \n",
    "    ##################################################################################\n",
    "    ###AGREGO LA DESCRIPCION DE CADA VALOR DE LOS NEMONICOS AL DICCIONARIO DE DATOS###\n",
    "    ##################################################################################\n",
    "    #creo subgrupos por nemonico#\n",
    "    grupos = diccionario_datos.groupby(['NEMONICO'])\n",
    "\n",
    "    #por cada variable del diccionario\n",
    "    for grupo in diccionario_datos['NEMONICO'].unique():\n",
    "        # try-catch por errores fuera de control\n",
    "        try:\n",
    "            #cargo el catálogo correspondiente\n",
    "            catalogo = pd.read_csv(f'{ruta_catalogos}/{grupo}.csv')\n",
    "            #obtengo el sub conjunto de datos correspondiente a la varibale\n",
    "            sub_df = grupos.get_group(grupo) \n",
    "            #contador que representa el rango de datos actual\n",
    "            contador = 0\n",
    "            #por cada uno de los indices del sub conjunto de datos\n",
    "            for idx in sub_df.index:\n",
    "                #obtener el valor de descripcion en catalogo actual\n",
    "                descripcion = catalogo.loc[contador, 'descrip']\n",
    "                #poner el valor de descripción en diccionario de datos\n",
    "                diccionario_datos.loc[idx,'DESCRIP'] = descripcion\n",
    "                contador += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    ######################################################################################\n",
    "    ###AGREGO LOS NEMONICOS QUE ESTÁN EN LA BASE DE DATOS AL DICCIONARIO DE DATOS FINAL###\n",
    "    ######################################################################################\n",
    "    #por cada fila en el diccionario de datos\n",
    "    for i in diccionario_datos.index:\n",
    "        #obtengo el nombre de la variable\n",
    "        nombre_variable = diccionario_datos.loc[i, 'NEMONICO']\n",
    "        #si la variable esta en las columnas del conjunto resultante del preprocesamiento\n",
    "        if nombre_variable in columnas:\n",
    "            #se agrega al diccionario de datos master\n",
    "            aux = aux.append(diccionario_datos.loc[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar columnas Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = aux.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar columnas con NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agregar columnas creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 'Numérico'\n",
    "longitud = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = 'Region económica de Mexico'\n",
    "nemonico = 'region'\n",
    "rango_claves = list(range(8))\n",
    "descrip = ['Noroeste', 'Norte', 'Noreste', 'Centro Occidente', 'Centro Sur', 'Golfo de México', 'Pacífico Sur', 'Península de Yucatán']\n",
    "\n",
    "for r,d in zip(rango_claves, descrip):\n",
    "    aux.loc[aux.shape[0]] = [nombre, nemonico, tipo, longitud, r, d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P9_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = 'Clasificacion del tipo de violencia obstétrica'\n",
    "nemonico = 'p9_8'\n",
    "rango_claves = list(range(4))\n",
    "descrip = ['Ninguno', 'Abuso y violencia', 'Atencion no autorizada', 'Ambos']\n",
    "\n",
    "for r,d in zip(rango_claves, descrip):\n",
    "    aux.loc[aux.shape[0]] = [nombre, nemonico, tipo, longitud, r, d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P9_1_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = 'No especificado'\n",
    "nemonico = 'p9_1_10'\n",
    "rango_claves = list(range(2))\n",
    "descrip = ['Si', 'No']\n",
    "\n",
    "for r,d in zip(rango_claves, descrip):\n",
    "    aux.loc[aux.shape[0]] = [nombre, nemonico, tipo, longitud, r, d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P9_5_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = 'No especificado'\n",
    "nemonico = 'p9_5_12'\n",
    "rango_claves = list(range(2))\n",
    "descrip = ['Si', 'No']\n",
    "\n",
    "for r,d in zip(rango_claves, descrip):\n",
    "    aux.loc[aux.shape[0]] = [nombre, nemonico, tipo, longitud, r, d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordenar de acuerdo al orden en la base de datos endireh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sorter(l): #https://stackoverflow.com/posts/66629450/revisions\n",
    "    \"\"\"\n",
    "    Create a dict from the list to map to 0..len(l)\n",
    "    Returns a mapper to map a series to this custom sort order\n",
    "    \"\"\"\n",
    "    sort_order = dict(zip(l, range(len(l)))) \n",
    "    return lambda s: s.map(lambda x: sort_order[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = aux.sort_values('NEMONICO', key=make_sorter(columnas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.reset_index(drop=True, inplace=True) #reajustar el índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borrar datos repetidos que tienen espacios extras, más de una descripción, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. cve_ent\n",
    "2. cve_mun\n",
    "1. dominio\n",
    "2. hogar\n",
    "3. t_instrum\n",
    "4. prog\n",
    "5. fac_viv\n",
    "6. fac_muj\n",
    "7. ump_dis\n",
    "8. est_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualizar valores modificados a mano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores que pasaron de ser 2 a ser 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[f'p1_4_{i}' for i in range(1,10)]\n",
    "\n",
    "['p2_8', 'p2_9', 'p2_11', 'p2_12', 'p2_13', 'p9_8_11', 'p9_8_13', 'p1_8', 'p3_2', 'p3_4', 'p3_7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores que pasaron de ser _b_ a tener un valor numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. p1_9 a 1\n",
    "2. [f'p1_10_{i}' for i in range(1, 5)] a 2\n",
    "3. [p2_8, p2_12, p2_15] A 9\n",
    "4. ['p2_14'] a 13\n",
    "5. [p3_3, p3_5, p3_6] a 9\n",
    "6. [p3_2, p3_4, p3_7]\\{above} a 2\n",
    "7. ['p9_8_11', 'p9_8_13', 'p9_8_14'] a 9\n",
    "8. P9_7 borrar b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores que pasaron de ser categóricos a numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y cambiar también el tipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#para DOMINIO\n",
    "{C: 0, R: 1, U: 2}\n",
    "\n",
    "#para T_INSTRUM\n",
    "{A1: 0, A2: 1, B1: 2, B2: 3, C1: 4, C2: 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores que fueron eliminados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [F'p9_1_{i}' for i in range(1,10)] se eliminaron los 9 y los b\n",
    "2. [F'p9_5_{i}' for i in range(1,12)] se eliminaron los 9 y los b\n",
    "\n",
    "Eliminar en general los b ya que no debe haber por la política de datos faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guardar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('datasets/diccionario_datos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
